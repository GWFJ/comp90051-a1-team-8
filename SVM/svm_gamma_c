###Choosing optimal gamma and C values for the imbalamanced dataset uisng GridSearchCV 5 splits:
##Reference for choosing the values: https://machinelearningmastery.com/cost-sensitive-svm-for-imbalanced-classification/
def svm_gamma_c(X, y):

    c_range = np.logspace(-2, 4, 7)  
    gamma_range = np.logspace(-6, 0, 7) 
    param_grid = dict(gamma=gamma_range, C=c_range)

    cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)  

    grid_best_params_list = []
    grid_best_score_list = []
    train_accuracy_list = []

    for fold, (train_index, test_index) in enumerate(cv.split(X, y)):
      X_train, X_test = X[train_index], X[test_index]
      y_train, y_test = y.iloc[train_index], y.iloc[test_index]

      grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv, n_jobs=-1)  
      grid.fit(X_train, y_train)

      grid_best_params_list.append(grid.best_params_)
      grid_best_score_list.append(grid.best_score_)

      svc = SVC(**grid.best_params_)
      svc.fit(X_train, y_train)
      train_accuracy = svc.score(X_train, y_train)
      train_accuracy_list.append(train_accuracy)

      # Print results for this fold
      print(f"Fold {fold + 1}:")
      print("  Best Parameters:", grid.best_params_)
      print("  Best Score:", grid.best_score_)
      print("  Train Accuracy:", train_accuracy)

    # Overall results after all folds
    print("Overall Results:")
    print("Average Best Parameters:", np.mean(grid_best_params_list, axis=0))
    print("Average Best Score:", np.mean(grid_best_score_list))
    print("Average Train Accuracy:", np.mean(train_accuracy_list))

    return grid_best_params_list, grid_best_score_list, train_accuracy_list
